{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "# from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcuate_accuracy_score(y_true, predictions):\n",
    "    assert len(y_true) == len(predictions), \"number of predictions does not equal original set length\"\n",
    "    numTotal = len(predictions)\n",
    "    numCorrect = numpy.count_nonzero(numpy.array(y_true) == numpy.array(predictions))\n",
    "    return numCorrect / numTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Analysis/Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>denial of normal the con be asked to comment o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just by being able to tweet this insufferable ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is retarded you too cute to be single tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thought of a real badass mongol style declarat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afro american basho</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content Label\n",
       "0  denial of normal the con be asked to comment o...     1\n",
       "1  just by being able to tweet this insufferable ...     1\n",
       "2  that is retarded you too cute to be single tha...     1\n",
       "3  thought of a real badass mongol style declarat...     1\n",
       "4                                afro american basho     1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"HateSpeechDataset.csv\")\n",
    "\n",
    "# Extract the needed columns\n",
    "df = df[['Content', 'Label']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        361594\n",
       "1         79305\n",
       "Label         7\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    440906.000000\n",
       "mean        226.116034\n",
       "std         277.813386\n",
       "min           1.000000\n",
       "25%          62.000000\n",
       "50%         119.000000\n",
       "75%         269.000000\n",
       "max        9998.000000\n",
       "Name: Content, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short_not_too_short = df[df.Label != \"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_lengths = df_short_not_too_short['Content'].str.len()\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,5), tight_layout=True)\n",
    "axs[0].hist(sentence_lengths.to_numpy(), bins=50, log=True)\n",
    "axs[1].hist(sentence_lengths.to_numpy(), bins=50, log=False)\n",
    "axs[0].set_ylabel(\"# of occurences (log)\")\n",
    "axs[0].set_xlabel(\"Length of message\")\n",
    "axs[1].set_ylabel(\"# of occurences\")\n",
    "axs[1].set_xlabel(\"Length of message\")\n",
    "fig.suptitle(\"Message length distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    361594\n",
       "1     79305\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short_not_too_short['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    440899.000000\n",
       "mean        226.119513\n",
       "std         277.814219\n",
       "min           1.000000\n",
       "25%          62.000000\n",
       "50%         119.000000\n",
       "75%         269.000000\n",
       "max        9998.000000\n",
       "Name: Content, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short_not_too_short['Content'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short_not_too_short = df_short_not_too_short[df_short_not_too_short['Content'].str.len() < 300]\n",
    "df_short_not_too_short = df_short_not_too_short[df_short_not_too_short['Content'].str.len() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50643</th>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115940</th>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409476</th>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32762</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105203</th>\n",
       "      <td>p</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398828</th>\n",
       "      <td>do not change it zzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40448</th>\n",
       "      <td>wsdfjneurovbnerpivijervnerovohjewrvnrnrvrejfir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376512</th>\n",
       "      <td>you are fucking gay wad i fucked your mum oh w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337241</th>\n",
       "      <td>gaaaaaaaaaaaaaaaaaaaaaaaaay you are fucking ga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378972</th>\n",
       "      <td>do not change it zzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440906 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content Label\n",
       "50643                                                   t     1\n",
       "115940                                                  v     0\n",
       "409476                                                  e     0\n",
       "32762                                                   a     1\n",
       "105203                                                  p     0\n",
       "...                                                   ...   ...\n",
       "398828  do not change it zzzzzzzzzzzzzzzzzzzzzzzzzzzzz...     0\n",
       "40448   wsdfjneurovbnerpivijervnerovohjewrvnrnrvrejfir...     1\n",
       "376512  you are fucking gay wad i fucked your mum oh w...     1\n",
       "337241  gaaaaaaaaaaaaaaaaaaaaaaaaay you are fucking ga...     1\n",
       "378972  do not change it zzzzzzzzzzzzzzzzzzzzzzzzzzzzz...     0\n",
       "\n",
       "[440906 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"Content\",inplace=False, key=lambda str: str.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    271100\n",
       "1     72279\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short_not_too_short['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7895066384374118"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "271100 / ( 271100+72279)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    343379.000000\n",
       "mean        108.869098\n",
       "std          72.442309\n",
       "min           2.000000\n",
       "25%          51.000000\n",
       "50%          91.000000\n",
       "75%         150.000000\n",
       "max         299.000000\n",
       "Name: Content, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short_not_too_short['Content'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9998"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc[378972].get(\"Content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df_short_not_too_short, test_size=0.5, random_state=random_state)  # 50% train, 25% validation, 25% test\n",
    "df_valid, df_test = train_test_split(df_valid, test_size=0.5, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training & Testing Models\n",
    "\n",
    "0) Random Choice -> 0.5\n",
    "1) BoW N most common words -> 0.8299183430987688\n",
    "2) BoW N most common TF-IDF -> 0.828528161220805\n",
    "3) latent semantic analysis (word2vec w/ Logistic) -> 0.8169025569340089\n",
    "4) word2vec w/ AdaBoost -> 0.8239967383074145\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.to_numpy()\n",
    "df_valid = df_valid.to_numpy()\n",
    "df_test = df_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train bag of words N most popular words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = set(string.punctuation)\n",
    "wordCount = defaultdict(int)\n",
    "for (sentence, label) in df_train:\n",
    "    r = ''.join([c for c in sentence.lower() if not c in sp])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14529, 'slut'),\n",
       " (12749, 'like'),\n",
       " (11410, 'article'),\n",
       " (10615, 'page'),\n",
       " (10328, 'would'),\n",
       " (9657, 'please'),\n",
       " (9345, 'people'),\n",
       " (9112, 'whatever'),\n",
       " (8711, 'one'),\n",
       " (8652, 'talk'),\n",
       " (8267, 'see'),\n",
       " (7824, 'know'),\n",
       " (7612, 'think'),\n",
       " (7251, 'get'),\n",
       " (6648, 'thanks'),\n",
       " (6527, 'wikipedia'),\n",
       " (6471, 'bitch'),\n",
       " (6388, 'face'),\n",
       " (5775, 'retweet'),\n",
       " (5719, 'want'),\n",
       " (5634, 'fuck'),\n",
       " (5539, 'good'),\n",
       " (5170, 'time'),\n",
       " (5105, 'go'),\n",
       " (4725, 'fucking'),\n",
       " (4646, 'edit'),\n",
       " (4587, 'love'),\n",
       " (4434, 'make'),\n",
       " (4257, 'also'),\n",
       " (4237, 'going'),\n",
       " (4145, 'stop'),\n",
       " (4127, 'well'),\n",
       " (4050, 'cannot'),\n",
       " (4018, 'us'),\n",
       " (3983, 'new'),\n",
       " (3977, 'need'),\n",
       " (3967, 'really'),\n",
       " (3947, 'could'),\n",
       " (3758, 'say'),\n",
       " (3744, 'right'),\n",
       " (3718, 'back'),\n",
       " (3704, 'thank'),\n",
       " (3558, 'even'),\n",
       " (3528, 'much'),\n",
       " (3527, 'look'),\n",
       " (3440, 'got'),\n",
       " (3403, 'use'),\n",
       " (3337, 'women'),\n",
       " (3255, 'take'),\n",
       " (3210, 'day'),\n",
       " (3129, 'let'),\n",
       " (3064, 'ass'),\n",
       " (3034, 'shit'),\n",
       " (3014, 'still'),\n",
       " (2980, 'user'),\n",
       " (2970, 'black'),\n",
       " (2953, 'blocked'),\n",
       " (2938, 'mr'),\n",
       " (2915, 'someone'),\n",
       " (2905, 'work'),\n",
       " (2902, 'never'),\n",
       " (2865, 'name'),\n",
       " (2865, 'editing'),\n",
       " (2748, 'many'),\n",
       " (2747, 'made'),\n",
       " (2709, 'first'),\n",
       " (2679, 'happy'),\n",
       " (2642, 'hate'),\n",
       " (2630, 'help'),\n",
       " (2615, 'white'),\n",
       " (2578, 'life'),\n",
       " (2514, 'address'),\n",
       " (2497, 'said'),\n",
       " (2482, 'man'),\n",
       " (2475, 'better'),\n",
       " (2445, 'articles'),\n",
       " (2443, 'something'),\n",
       " (2424, 'hi'),\n",
       " (2407, 'trump'),\n",
       " (2398, 'utc'),\n",
       " (2397, 'sure'),\n",
       " (2360, 'pages'),\n",
       " (2348, 'section'),\n",
       " (2348, 'oh'),\n",
       " (2344, 'joy'),\n",
       " (2321, 'tears'),\n",
       " (2320, 'edits'),\n",
       " (2305, 'little'),\n",
       " (2288, 'find'),\n",
       " (2277, 'old'),\n",
       " (2252, 'world'),\n",
       " (2245, 'wrong'),\n",
       " (2239, 'point'),\n",
       " (2228, 'two'),\n",
       " (2220, 'sorry'),\n",
       " (2220, 'put'),\n",
       " (2190, 'read'),\n",
       " (2174, 'keep'),\n",
       " (2170, 'come'),\n",
       " (2140, 'another'),\n",
       " (2115, 'great'),\n",
       " (2109, 'feel'),\n",
       " (2104, 'nothing'),\n",
       " (2101, 'list'),\n",
       " (2099, 'anyone'),\n",
       " (2086, 'best'),\n",
       " (2074, 'source'),\n",
       " (2059, 'discussion'),\n",
       " (2022, 'since'),\n",
       " (2017, 'means'),\n",
       " (2006, 'link'),\n",
       " (2001, 'yes'),\n",
       " (1996, 'used'),\n",
       " (1985, 'already'),\n",
       " (1978, 'vandalism'),\n",
       " (1965, 'laughing'),\n",
       " (1964, 'anything'),\n",
       " (1953, 'year'),\n",
       " (1951, 'country'),\n",
       " (1941, 'information'),\n",
       " (1932, 'give'),\n",
       " (1903, 'sources'),\n",
       " (1898, 'thing'),\n",
       " (1889, 'tell'),\n",
       " (1878, 'person'),\n",
       " (1878, 'done'),\n",
       " (1875, 'added'),\n",
       " (1872, 'actually'),\n",
       " (1848, 'every'),\n",
       " (1843, 'removed'),\n",
       " (1840, 'last'),\n",
       " (1838, 'everyone'),\n",
       " (1796, 'ever'),\n",
       " (1781, 'wiki'),\n",
       " (1781, 'hope'),\n",
       " (1781, 'bitches'),\n",
       " (1765, 'continue'),\n",
       " (1754, 'bad'),\n",
       " (1753, 'real'),\n",
       " (1753, 'nice'),\n",
       " (1751, 'always'),\n",
       " (1732, 'comment'),\n",
       " (1731, 'hey'),\n",
       " (1724, 'free'),\n",
       " (1718, 'mean'),\n",
       " (1714, 'loud'),\n",
       " (1714, 'block'),\n",
       " (1710, 'men'),\n",
       " (1701, 'believe'),\n",
       " (1687, 'change'),\n",
       " (1683, 'cool'),\n",
       " (1680, 'getting'),\n",
       " (1661, 'around'),\n",
       " (1654, 'try'),\n",
       " (1646, 'stupid'),\n",
       " (1637, 'today'),\n",
       " (1633, 'lot'),\n",
       " (1628, 'reason'),\n",
       " (1628, 'might'),\n",
       " (1621, 'without'),\n",
       " (1618, 'call'),\n",
       " (1616, 'years'),\n",
       " (1614, 'things'),\n",
       " (1612, 'trying'),\n",
       " (1612, 'says'),\n",
       " (1606, 'though'),\n",
       " (1596, 'problem'),\n",
       " (1592, 'comments'),\n",
       " (1577, 'show'),\n",
       " (1576, 'thought'),\n",
       " (1576, 'long'),\n",
       " (1556, 'seems'),\n",
       " (1516, 'fact'),\n",
       " (1502, 'else'),\n",
       " (1497, 'must'),\n",
       " (1491, 'deletion'),\n",
       " (1490, 'deleted'),\n",
       " (1474, 'agree'),\n",
       " (1461, 'yeah'),\n",
       " (1453, 'place'),\n",
       " (1453, 'called'),\n",
       " (1449, 'maybe'),\n",
       " (1449, 'hoe'),\n",
       " (1445, 'leave'),\n",
       " (1438, 'big'),\n",
       " (1423, 'history'),\n",
       " (1420, 'god'),\n",
       " (1407, 'support'),\n",
       " (1407, 'needs'),\n",
       " (1406, 'understand'),\n",
       " (1400, 'pussy'),\n",
       " (1395, 'woman'),\n",
       " (1394, 'enough'),\n",
       " (1385, 'making'),\n",
       " (1374, 'k'),\n",
       " (1368, 'next'),\n",
       " (1362, 'left'),\n",
       " (1355, 'shut'),\n",
       " (1347, 'image'),\n",
       " (1343, 'internet'),\n",
       " (1333, 'redirect'),\n",
       " (1332, 'saying'),\n",
       " (1332, 'idea'),\n",
       " (1330, 'care'),\n",
       " (1319, 'welcome'),\n",
       " (1319, 'post'),\n",
       " (1318, 'gay'),\n",
       " (1305, 'makes'),\n",
       " (1303, 'probably'),\n",
       " (1293, 'okay'),\n",
       " (1290, 'school'),\n",
       " (1290, 'case'),\n",
       " (1287, 'check'),\n",
       " (1285, 'hello'),\n",
       " (1279, 'question'),\n",
       " (1276, 'personal'),\n",
       " (1271, 'vandalize'),\n",
       " (1267, 'hoes'),\n",
       " (1265, 'part'),\n",
       " (1261, 'reply'),\n",
       " (1260, 'looks'),\n",
       " (1252, 'looking'),\n",
       " (1226, 'opinion'),\n",
       " (1224, 'yet'),\n",
       " (1222, 'delete'),\n",
       " (1219, 'using'),\n",
       " (1202, 'times'),\n",
       " (1201, 'message'),\n",
       " (1200, 'style'),\n",
       " (1199, 'live'),\n",
       " (1198, 'remove'),\n",
       " (1187, 'damn'),\n",
       " (1180, 'je'),\n",
       " (1179, 'found'),\n",
       " (1179, 'away'),\n",
       " (1170, 'ok'),\n",
       " (1166, 'guy'),\n",
       " (1159, 'request'),\n",
       " (1153, 'kind'),\n",
       " (1152, 'talking'),\n",
       " (1147, 'note'),\n",
       " (1145, 'game'),\n",
       " (1142, 'girl'),\n",
       " (1138, 'bit'),\n",
       " (1137, 'american'),\n",
       " (1120, 'text'),\n",
       " (1116, 'far'),\n",
       " (1115, 'info'),\n",
       " (1114, 'war'),\n",
       " (1113, 'links'),\n",
       " (1109, 'least'),\n",
       " (1108, 'reverted'),\n",
       " (1106, 'content'),\n",
       " (1104, 'e'),\n",
       " (1100, 'english'),\n",
       " (1096, 'start'),\n",
       " (1092, 'true'),\n",
       " (1084, 'home'),\n",
       " (1062, 'watch'),\n",
       " (1062, 'hard'),\n",
       " (1057, 'news'),\n",
       " (1057, 'ask'),\n",
       " (1055, 'days'),\n",
       " (1054, 'picture'),\n",
       " (1049, 'end'),\n",
       " (1047, 'job'),\n",
       " (1046, 'way'),\n",
       " (1043, 'seen'),\n",
       " (1043, 'pretty'),\n",
       " (1042, 'issue'),\n",
       " (1041, 'account'),\n",
       " (1038, 'review'),\n",
       " (1038, 'others'),\n",
       " (1036, 'non'),\n",
       " (1034, 'view'),\n",
       " (1021, 'matter'),\n",
       " (1020, 'family'),\n",
       " (1002, 'mind'),\n",
       " (1001, 'america'),\n",
       " (995, 'states'),\n",
       " (993, 'reference'),\n",
       " (992, 'control'),\n",
       " (989, 'money'),\n",
       " (987, 'protocol'),\n",
       " (986, 'stay'),\n",
       " (986, 'everything'),\n",
       " (985, 'move'),\n",
       " (982, 'muslims'),\n",
       " (981, 'vagina'),\n",
       " (974, 'rather'),\n",
       " (972, 'sad'),\n",
       " (970, 'state'),\n",
       " (969, 'guess'),\n",
       " (968, 'star'),\n",
       " (963, 'different'),\n",
       " (962, 'wish'),\n",
       " (958, 'correct'),\n",
       " (953, 'seem'),\n",
       " (952, 'wait'),\n",
       " (951, 'gun'),\n",
       " (951, 'either'),\n",
       " (941, 'hell'),\n",
       " (937, 'attack'),\n",
       " (933, 'soon'),\n",
       " (926, 'head'),\n",
       " (923, 'guys'),\n",
       " (922, 'full'),\n",
       " (913, 'policy'),\n",
       " (912, 'instead'),\n",
       " (910, 'muslim'),\n",
       " (904, 'friends'),\n",
       " (897, 'friend'),\n",
       " (893, 'refugees'),\n",
       " (893, 'nigga'),\n",
       " (890, 'book'),\n",
       " (888, 'liberals'),\n",
       " (888, 'girls'),\n",
       " (887, 'video'),\n",
       " (880, 'template'),\n",
       " (879, 'cheers'),\n",
       " (876, 'references'),\n",
       " (876, 'however'),\n",
       " (873, 'whole'),\n",
       " (872, 'united'),\n",
       " (871, 'administrator'),\n",
       " (867, 'anyway'),\n",
       " (865, 'adding'),\n",
       " (864, 'hand'),\n",
       " (861, 'stuff'),\n",
       " (859, 'team'),\n",
       " (858, 'editors'),\n",
       " (854, 'revert'),\n",
       " (843, 'site'),\n",
       " (839, 'sock'),\n",
       " (838, 'trash'),\n",
       " (836, 'editor'),\n",
       " (835, 'main'),\n",
       " (834, 'title'),\n",
       " (831, 'reliable'),\n",
       " (830, 'course'),\n",
       " (828, 'version'),\n",
       " (828, 'high'),\n",
       " (828, 'created'),\n",
       " (827, 'working'),\n",
       " (826, 'sense'),\n",
       " (823, 'kids'),\n",
       " (820, 'smiley'),\n",
       " (820, 'play'),\n",
       " (817, 'week'),\n",
       " (808, 'suck'),\n",
       " (804, 'explain'),\n",
       " (804, 'box'),\n",
       " (804, 'ago'),\n",
       " (803, 'vote'),\n",
       " (800, 'funny'),\n",
       " (797, 'project'),\n",
       " (797, 'anti'),\n",
       " (795, 'perhaps'),\n",
       " (795, 'fun'),\n",
       " (794, 'wanted'),\n",
       " (794, 'remember'),\n",
       " (794, 'penis'),\n",
       " (794, 'considered'),\n",
       " (794, 'common'),\n",
       " (792, 'original'),\n",
       " (785, 'term'),\n",
       " (785, 'quite'),\n",
       " (784, 'music'),\n",
       " (783, 'number'),\n",
       " (782, 'p'),\n",
       " (782, 'faggot'),\n",
       " (781, 'clearly'),\n",
       " (780, 'follow'),\n",
       " (779, 'warning'),\n",
       " (779, 'red'),\n",
       " (779, 'city'),\n",
       " (779, 'allowed'),\n",
       " (778, 'idiot'),\n",
       " (777, 'changed'),\n",
       " (775, 'saw'),\n",
       " (775, 'lol'),\n",
       " (774, 'children'),\n",
       " (773, 'maga'),\n",
       " (772, 'party'),\n",
       " (769, 'death'),\n",
       " (768, 'illegal'),\n",
       " (761, 'top'),\n",
       " (758, 'words'),\n",
       " (757, 'doctors'),\n",
       " (756, 'house'),\n",
       " (756, 'alone'),\n",
       " (755, 'less'),\n",
       " (755, 'fine'),\n",
       " (755, 'etc'),\n",
       " (755, 'die'),\n",
       " (754, 'tag'),\n",
       " (748, 'example'),\n",
       " (746, 'middle'),\n",
       " (745, 'changes'),\n",
       " (744, 'sandbox'),\n",
       " (744, 'consensus'),\n",
       " (743, 'racist'),\n",
       " (742, 'given'),\n",
       " (740, 'learn'),\n",
       " (738, 'mention'),\n",
       " (735, 'dumb'),\n",
       " (730, 'heart'),\n",
       " (727, 'regarding'),\n",
       " (727, 'night'),\n",
       " (724, 'truth'),\n",
       " (724, 'group'),\n",
       " (723, 'media'),\n",
       " (721, 'known'),\n",
       " (720, 'evidence'),\n",
       " (717, 'three'),\n",
       " (716, 'clear'),\n",
       " (713, 'kill'),\n",
       " (713, 'islam'),\n",
       " (713, 'haha'),\n",
       " (711, 'open'),\n",
       " (707, 'second'),\n",
       " (706, 'song'),\n",
       " (706, 'jews'),\n",
       " (705, 'calling'),\n",
       " (697, 'suggest'),\n",
       " (693, 'told'),\n",
       " (692, 'sucks'),\n",
       " (691, 'wow'),\n",
       " (690, 'class'),\n",
       " (688, 'per'),\n",
       " (683, 'self'),\n",
       " (683, 'future'),\n",
       " (682, 'eyes'),\n",
       " (680, 'boy'),\n",
       " (678, 'race'),\n",
       " (678, 'coming'),\n",
       " (677, 'dead'),\n",
       " (674, 'heard'),\n",
       " (674, 'current'),\n",
       " (670, 'date'),\n",
       " (668, 'material'),\n",
       " (667, 'possible'),\n",
       " (666, 'antifa'),\n",
       " (665, 'immigrants'),\n",
       " (664, 'write'),\n",
       " (663, 'able'),\n",
       " (662, 'language'),\n",
       " (660, 'website'),\n",
       " (657, 'ya'),\n",
       " (656, 'u'),\n",
       " (656, 'piece'),\n",
       " (651, 'via'),\n",
       " (649, 'happens'),\n",
       " (649, 'b'),\n",
       " (648, 'contributions'),\n",
       " (648, 'ahead'),\n",
       " (645, 'came'),\n",
       " (644, 'sex'),\n",
       " (643, 'line'),\n",
       " (640, 'notable'),\n",
       " (637, 'important'),\n",
       " (636, 'government'),\n",
       " (633, 'exactly'),\n",
       " (633, 'encyclopedia'),\n",
       " (630, 'users'),\n",
       " (628, 'single'),\n",
       " (627, 'started'),\n",
       " (625, 'simply'),\n",
       " (624, 'went'),\n",
       " (621, 'beautiful'),\n",
       " (618, 'run'),\n",
       " (617, 'rest'),\n",
       " (616, 'notice'),\n",
       " (615, 'gone'),\n",
       " (613, 'thinking'),\n",
       " (613, 'story'),\n",
       " (612, 'side'),\n",
       " (611, 'report'),\n",
       " (610, 'food'),\n",
       " (609, 'rights'),\n",
       " (608, 'unless'),\n",
       " (607, 'written'),\n",
       " (607, 'gets'),\n",
       " (606, 'mentioned'),\n",
       " (605, 'c'),\n",
       " (605, 'based'),\n",
       " (604, 'conservatives'),\n",
       " (603, 'images'),\n",
       " (601, 'film'),\n",
       " (600, 'removing'),\n",
       " (600, 'rape'),\n",
       " (600, 'applicable'),\n",
       " (598, 'zero'),\n",
       " (598, 'twitter'),\n",
       " (598, 'needed'),\n",
       " (597, 'public'),\n",
       " (597, 'immigration'),\n",
       " (596, 'president'),\n",
       " (596, 'eat'),\n",
       " (594, 'sexist'),\n",
       " (591, 'dude'),\n",
       " (590, 'living'),\n",
       " (590, 'americans'),\n",
       " (589, 'listed'),\n",
       " (589, 'law'),\n",
       " (589, 'father'),\n",
       " (587, 'interested'),\n",
       " (587, 'answer'),\n",
       " (586, 'taking'),\n",
       " (585, 'goes'),\n",
       " (585, 'color'),\n",
       " (585, 'align'),\n",
       " (584, 'retarded'),\n",
       " (582, 'subject'),\n",
       " (582, 'pictures'),\n",
       " (581, 'fair'),\n",
       " (579, 'hear'),\n",
       " (578, 'son'),\n",
       " (576, 'human'),\n",
       " (576, 'asshole'),\n",
       " (575, 'reading'),\n",
       " (575, 'claim'),\n",
       " (573, 'uk'),\n",
       " (573, 'pay'),\n",
       " (573, 'order'),\n",
       " (573, 'official'),\n",
       " (573, 'later'),\n",
       " (573, 'consider'),\n",
       " (573, 'almost'),\n",
       " (572, 'stand'),\n",
       " (572, 'seriously'),\n",
       " (572, 'birthday'),\n",
       " (571, 'chinese'),\n",
       " (570, 'issues'),\n",
       " (568, 'recent'),\n",
       " (567, 'response'),\n",
       " (567, 'kat'),\n",
       " (566, 'took'),\n",
       " (566, 'power'),\n",
       " (566, 'movie'),\n",
       " (565, 'reasons'),\n",
       " (563, 'fat'),\n",
       " (562, 'f'),\n",
       " (561, 'wants'),\n",
       " (561, 'attacks'),\n",
       " (560, 'regards'),\n",
       " (557, 'poor'),\n",
       " (556, 'smiling'),\n",
       " (556, 'national'),\n",
       " (556, 'email'),\n",
       " (553, 'reverting'),\n",
       " (553, 'moved'),\n",
       " (552, 'glad'),\n",
       " (550, 'set'),\n",
       " (549, 'dog'),\n",
       " (548, 'taken'),\n",
       " (547, 'following'),\n",
       " (545, 'photo'),\n",
       " (545, 'asked'),\n",
       " (543, 'obama'),\n",
       " (543, 'lost'),\n",
       " (542, 'category'),\n",
       " (541, 'ugly'),\n",
       " (541, 'fan'),\n",
       " (540, 'relevant'),\n",
       " (540, 'nonsense'),\n",
       " (540, 'discuss'),\n",
       " (539, 'past'),\n",
       " (538, 'amazing'),\n",
       " (536, 'test'),\n",
       " (536, 'related'),\n",
       " (536, 'happened'),\n",
       " (536, 'exist'),\n",
       " (536, 'copy'),\n",
       " (536, 'completely'),\n",
       " (535, 'create'),\n",
       " (534, 'tried'),\n",
       " (534, 'sick'),\n",
       " (533, 'fix'),\n",
       " (533, 'barn'),\n",
       " (532, 'together'),\n",
       " (532, 'morning'),\n",
       " (530, 'topic'),\n",
       " (530, 'hit'),\n",
       " (530, 'due'),\n",
       " (529, 'rules'),\n",
       " (529, 'facts'),\n",
       " (529, 'become'),\n",
       " (528, 'com'),\n",
       " (527, 'names'),\n",
       " (527, 'crying'),\n",
       " (527, 'banned'),\n",
       " (524, 'statement'),\n",
       " (524, 'area'),\n",
       " (523, 'countries'),\n",
       " (521, 'political'),\n",
       " (521, 'hands'),\n",
       " (520, 'watching'),\n",
       " (520, 'television'),\n",
       " (517, 'shows'),\n",
       " (517, 'retard'),\n",
       " (517, 'british'),\n",
       " (517, 'baby'),\n",
       " (515, 'wonder'),\n",
       " (515, 'definitely'),\n",
       " (514, 'whether'),\n",
       " (513, 'society'),\n",
       " (513, 'posted'),\n",
       " (513, 'obviously'),\n",
       " (512, 'speak'),\n",
       " (512, 'research'),\n",
       " (512, 'india'),\n",
       " (508, 'sentence'),\n",
       " (506, 'ones'),\n",
       " (506, 'lead'),\n",
       " (505, 'sign'),\n",
       " (505, 'key'),\n",
       " (504, 'currently'),\n",
       " (504, 'comes'),\n",
       " (503, 'fight'),\n",
       " (503, 'disagree'),\n",
       " (503, 'crap'),\n",
       " (502, 'niggas'),\n",
       " (500, 'act'),\n",
       " (497, 'young'),\n",
       " (496, 'whore'),\n",
       " (496, 'john'),\n",
       " (495, 'hours'),\n",
       " (493, 'deal'),\n",
       " (492, 'wrote'),\n",
       " (491, 'youtube'),\n",
       " (491, 'pa'),\n",
       " (491, 'interesting'),\n",
       " (491, 'especially'),\n",
       " (490, 'police'),\n",
       " (489, 'half'),\n",
       " (489, 'appreciate'),\n",
       " (488, 'several'),\n",
       " (486, 'tomorrow'),\n",
       " (486, 'anymore'),\n",
       " (486, 'although'),\n",
       " (483, 'problems'),\n",
       " (483, 'business'),\n",
       " (482, 'sounds'),\n",
       " (481, 'jewish'),\n",
       " (480, 'evil'),\n",
       " (479, 'win'),\n",
       " (479, 'quote'),\n",
       " (477, 'provide'),\n",
       " (477, 'dear'),\n",
       " (476, 'flag'),\n",
       " (476, 'bring'),\n",
       " (475, 'meet'),\n",
       " (475, 'knows'),\n",
       " (473, 'writing'),\n",
       " (473, 'respect'),\n",
       " (473, 'include'),\n",
       " (473, 'copyright'),\n",
       " (472, 'touch'),\n",
       " (472, 'noticed'),\n",
       " (472, 'certainly'),\n",
       " (471, 'system'),\n",
       " (471, 'attention'),\n",
       " (469, 'couple'),\n",
       " (469, 'border'),\n",
       " (468, 'season'),\n",
       " (468, 'opinions'),\n",
       " (468, 'lives'),\n",
       " (468, 'brother'),\n",
       " (467, 'tonight'),\n",
       " (467, 'immigrant'),\n",
       " (467, 'child'),\n",
       " (466, 'light'),\n",
       " (466, 'appropriate'),\n",
       " (465, 'killed'),\n",
       " (463, 'none'),\n",
       " (463, 'easy'),\n",
       " (461, 'recently'),\n",
       " (461, 'according'),\n",
       " (460, 'shame'),\n",
       " (458, 'normal'),\n",
       " (457, 'played'),\n",
       " (456, 'type'),\n",
       " (456, 'born'),\n",
       " (456, 'ban'),\n",
       " (456, 'absolutely'),\n",
       " (455, 'works'),\n",
       " (454, 'small'),\n",
       " (454, 'lie'),\n",
       " (453, 'disgusting'),\n",
       " (452, 'nigger'),\n",
       " (452, 'blacks'),\n",
       " (451, 'worth'),\n",
       " (451, 'padding'),\n",
       " (450, 'deserve'),\n",
       " (450, 'cont'),\n",
       " (450, 'aware'),\n",
       " (448, 'mother'),\n",
       " (447, 'thinks'),\n",
       " (447, 'migrants'),\n",
       " (447, 'general'),\n",
       " (446, 'longer'),\n",
       " (446, 'google'),\n",
       " (446, 'community'),\n",
       " (445, 'hot'),\n",
       " (445, 'difference'),\n",
       " (443, 'ready'),\n",
       " (443, 'interest'),\n",
       " (443, 'female'),\n",
       " (443, 'fake'),\n",
       " (442, 'za'),\n",
       " (441, 'worked'),\n",
       " (441, 'football'),\n",
       " (441, 'deleting'),\n",
       " (440, 'sound'),\n",
       " (440, 'obvious'),\n",
       " (440, 'months'),\n",
       " (440, 'million'),\n",
       " (439, 'happen'),\n",
       " (438, 'gave'),\n",
       " (438, 'entire'),\n",
       " (437, 'playing'),\n",
       " (437, 'hundred'),\n",
       " (435, 'points'),\n",
       " (434, 'chance'),\n",
       " (433, 'short'),\n",
       " (433, 'nobody'),\n",
       " (433, 'car'),\n",
       " (430, 'seeing'),\n",
       " (430, 'band'),\n",
       " (429, 'trouble'),\n",
       " (429, 'space'),\n",
       " (428, 'telling'),\n",
       " (428, 'sort'),\n",
       " (428, 'giving'),\n",
       " (428, 'appears'),\n",
       " (426, 'major'),\n",
       " (426, 'cute'),\n",
       " (425, 'summer'),\n",
       " (425, 'close'),\n",
       " (424, 'weekend'),\n",
       " (424, 'lying'),\n",
       " (424, 'break'),\n",
       " (423, 'useful'),\n",
       " (422, 'joke'),\n",
       " (422, 'edited'),\n",
       " (421, 'otherwise'),\n",
       " (421, 'involved'),\n",
       " (419, 'trumpisatraitor'),\n",
       " (419, 'games'),\n",
       " (419, 'changing'),\n",
       " (418, 'skin'),\n",
       " (416, 'speech'),\n",
       " (416, 'including'),\n",
       " (416, 'crazy'),\n",
       " (414, 'miss'),\n",
       " (414, 'bullshit'),\n",
       " (413, 'trans'),\n",
       " (413, 'totally'),\n",
       " (413, 'complete'),\n",
       " (413, 'along'),\n",
       " (412, 'unblock'),\n",
       " (412, 'mistake'),\n",
       " (411, 'questions'),\n",
       " (411, 'cut'),\n",
       " (410, 'serious'),\n",
       " (410, 'likely'),\n",
       " (410, 'hold'),\n",
       " (409, 'g'),\n",
       " (409, 'blue'),\n",
       " (407, 'join'),\n",
       " (407, 'faith'),\n",
       " (407, 'behind'),\n",
       " (406, 'ill'),\n",
       " (405, 'computer'),\n",
       " (404, 'similar'),\n",
       " (404, 'rude'),\n",
       " (404, 'mine'),\n",
       " (403, 'rule'),\n",
       " (402, 'knowledge'),\n",
       " (402, 'four'),\n",
       " (402, 'bill'),\n",
       " (401, 'proof'),\n",
       " (401, 'neutral'),\n",
       " (401, 'afd'),\n",
       " (400, 'indeed'),\n",
       " (400, 'abuse'),\n",
       " (399, 'social'),\n",
       " (399, 'search'),\n",
       " (399, 'merge'),\n",
       " (399, 'claims'),\n",
       " (397, 'wondering'),\n",
       " (397, 'puppet'),\n",
       " (396, 'series'),\n",
       " (396, 'mom'),\n",
       " (395, 'worst'),\n",
       " (395, 'ribs'),\n",
       " (395, 'annoying'),\n",
       " (394, 'false'),\n",
       " (392, 'shall'),\n",
       " (392, 'positive'),\n",
       " (392, 'nazi'),\n",
       " (391, 'speedy'),\n",
       " (391, 'low'),\n",
       " (391, 'jpg'),\n",
       " (390, 'simple'),\n",
       " (390, 'awesome'),\n",
       " (389, 'university'),\n",
       " (389, 'send'),\n",
       " (389, 'europe'),\n",
       " (388, 'summary'),\n",
       " (388, 'sometimes'),\n",
       " (388, 'realize'),\n",
       " (388, 'included'),\n",
       " (387, 'action'),\n",
       " (386, 'web'),\n",
       " (386, 'finally'),\n",
       " (386, 'culture'),\n",
       " (386, 'contact'),\n",
       " (385, 'fixed'),\n",
       " (385, 'buildthatwall'),\n",
       " (384, 'smile'),\n",
       " (384, 'moment'),\n",
       " (384, 'forward'),\n",
       " (382, 'suit'),\n",
       " (382, 'perfect'),\n",
       " (382, 'entry'),\n",
       " (382, 'behavior'),\n",
       " (382, 'asking'),\n",
       " (381, 'enjoy'),\n",
       " (381, 'album'),\n",
       " (380, 'useless'),\n",
       " (380, 'somebody'),\n",
       " (380, 'shot'),\n",
       " (380, 'large'),\n",
       " (379, 'listen'),\n",
       " (377, 'solid'),\n",
       " (377, 'ha'),\n",
       " (376, 'vandalizing'),\n",
       " (375, 'dont'),\n",
       " (374, 'ridiculous'),\n",
       " (374, 'german'),\n",
       " (374, 'body'),\n",
       " (373, 'sta'),\n",
       " (372, 'south'),\n",
       " (372, 'paragraph'),\n",
       " (372, 'notability'),\n",
       " (372, 'hair'),\n",
       " (371, 'forget'),\n",
       " (370, 'specific'),\n",
       " (370, 'month'),\n",
       " (370, 'kid'),\n",
       " (370, 'form'),\n",
       " (370, 'books'),\n",
       " (370, 'apparently'),\n",
       " (369, 'turn'),\n",
       " (369, 'near'),\n",
       " (368, 'water'),\n",
       " (368, 'special'),\n",
       " (368, 'cunt'),\n",
       " (368, 'creating'),\n",
       " (368, 'blocking'),\n",
       " (368, 'actual'),\n",
       " (365, 'proud'),\n",
       " (365, 'earth'),\n",
       " (365, 'bot'),\n",
       " (364, 'citation'),\n",
       " (364, 'cat'),\n",
       " (363, 'wife'),\n",
       " (363, 'parents'),\n",
       " (363, 'lies'),\n",
       " (362, 'online'),\n",
       " (362, 'crime'),\n",
       " (361, 'liberal'),\n",
       " (360, 'npov'),\n",
       " (360, 'luck'),\n",
       " (360, 'final'),\n",
       " (360, 'beat'),\n",
       " (359, 'update'),\n",
       " (359, 'peace'),\n",
       " (359, 'meant'),\n",
       " (359, 'log'),\n",
       " (359, 'isis'),\n",
       " (358, 'within'),\n",
       " (358, 'training'),\n",
       " (358, 'rock'),\n",
       " (358, 'favorite'),\n",
       " (358, 'dirty'),\n",
       " (357, 'standard'),\n",
       " (357, 'quality'),\n",
       " (357, 'indian'),\n",
       " (357, 'feeling'),\n",
       " (356, 'username'),\n",
       " (356, 'supposed'),\n",
       " (356, 'proper'),\n",
       " (356, 'buy'),\n",
       " (354, 'starting'),\n",
       " (354, 'mad'),\n",
       " (354, 'admin'),\n",
       " (352, 'therefore'),\n",
       " (352, 'level'),\n",
       " (352, 'except'),\n",
       " (351, 'thread'),\n",
       " (351, 'sto'),\n",
       " (351, 'doubt'),\n",
       " (351, 'clean'),\n",
       " (351, 'bunch'),\n",
       " (350, 'sent'),\n",
       " (350, 'often'),\n",
       " (350, 'boys'),\n",
       " (349, 'wink'),\n",
       " (349, 'views'),\n",
       " (349, 'ti'),\n",
       " (349, 'episode'),\n",
       " (347, 'straight'),\n",
       " (347, 'likes'),\n",
       " (346, 'table'),\n",
       " (346, 'status'),\n",
       " (346, 'company'),\n",
       " (344, 'process'),\n",
       " (344, 'previous'),\n",
       " (344, 'asian'),\n",
       " (343, 'whites'),\n",
       " (343, 'size'),\n",
       " (343, 'contributing'),\n",
       " (343, 'appear'),\n",
       " (341, 'posts'),\n",
       " (341, 'experiment'),\n",
       " (341, 'cover'),\n",
       " (340, 'worse'),\n",
       " (340, 'strong'),\n",
       " (340, 'map'),\n",
       " (340, 'london'),\n",
       " (340, 'legal'),\n",
       " (340, 'fucked'),\n",
       " (340, 'debate'),\n",
       " (340, 'dark'),\n",
       " (340, 'christian'),\n",
       " (340, 'argument'),\n",
       " (340, 'accept'),\n",
       " (339, 'named'),\n",
       " (338, 'protected'),\n",
       " (338, 'kiss'),\n",
       " (337, 'smirk'),\n",
       " (336, 'mouth'),\n",
       " (336, 'bi'),\n",
       " (335, 'waiting'),\n",
       " (335, 'dispute'),\n",
       " (335, 'bet'),\n",
       " (335, 'award'),\n",
       " (333, 'separate'),\n",
       " (333, 'result'),\n",
       " (332, 'running'),\n",
       " (332, 'male'),\n",
       " (331, 'present'),\n",
       " (331, 'effort'),\n",
       " (330, 'trust'),\n",
       " (330, 'sourced'),\n",
       " (330, 'record'),\n",
       " (330, 'protect'),\n",
       " (330, 'huge'),\n",
       " (330, 'front'),\n",
       " (330, 'early'),\n",
       " (329, 'piss'),\n",
       " (329, 'pathetic'),\n",
       " (329, 'french'),\n",
       " (328, 'religion'),\n",
       " (328, 'jesus'),\n",
       " (328, 'club'),\n",
       " (328, 'bird'),\n",
       " (328, 'belong'),\n",
       " (327, 'looked'),\n",
       " (327, 'lists'),\n",
       " (327, 'ignorant'),\n",
       " (327, 'figure'),\n",
       " (327, 'avoid'),\n",
       " (326, 'street'),\n",
       " (326, 'laws'),\n",
       " (326, 'fightback'),\n",
       " (325, 'random'),\n",
       " (325, 'quick'),\n",
       " (324, 'total'),\n",
       " (324, 'particular'),\n",
       " (324, 'missing'),\n",
       " (324, 'definition'),\n",
       " (322, 'outside'),\n",
       " (322, 'fans'),\n",
       " (322, 'age'),\n",
       " (321, 'weeks'),\n",
       " (321, 'town'),\n",
       " (321, 'dad'),\n",
       " (320, 'tone'),\n",
       " (320, 'putting'),\n",
       " (320, 'admins'),\n",
       " (319, 'valid'),\n",
       " (319, 'resist'),\n",
       " (319, 'reported'),\n",
       " (319, 'posting'),\n",
       " (318, 'members'),\n",
       " (318, 'died'),\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords = stopwords.words(\"english\")\n",
    "counts = [(wordCount[x], x) for x in wordCount if not x in stopWords]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureCountN(datum, wordsN, wordIdN):\n",
    "    feat = [0]*len(wordsN)\n",
    "    r = ''.join([c for c in datum.lower() if not c in sp])\n",
    "    for w in r.split():\n",
    "        if w in wordsN:\n",
    "            feat[wordIdN[w]] += 1\n",
    "    feat.append(1) # offset\n",
    "    return feat\n",
    "\n",
    "def trainModelCounts(dictSize, reg_C, trainSet, validSet):\n",
    "    wordsN = [x[1] for x in counts[:dictSize]]\n",
    "    wordIdN = dict(zip(wordsN, range(len(wordsN))))\n",
    "\n",
    "    X_train = [featureCountN(sentence, wordsN, wordIdN) for (sentence,_) in trainSet]\n",
    "    y_train = [label for (_,label) in trainSet]\n",
    "\n",
    "    X_valid = [featureCountN(sentence, wordsN, wordIdN) for (sentence,_) in validSet]\n",
    "    y_valid = [label for (_,label) in validSet]\n",
    "\n",
    "    # X_test = [featureCountN(sentence, wordsN, wordIdN) for (sentence,_) in testSet]\n",
    "    # y_test = [label for (_,label) in testSet]\n",
    "    mod = linear_model.LogisticRegression(C=reg_C, random_state=random_state)\n",
    "    mod.fit(X_train,y_train)\n",
    "    pred_valid = mod.predict(X_valid)\n",
    "    correct = pred_valid == y_valid\n",
    "    return (numpy.sum(correct) / len(correct), mod)\n",
    "\n",
    "def trainModel_BoWPop(dictSize, reg_C, trainSet):\n",
    "    wordsN = [x[1] for x in counts[:dictSize]]\n",
    "    wordIdN = dict(zip(wordsN, range(len(wordsN))))\n",
    "\n",
    "    X_train = [featureCountN(sentence, wordsN, wordIdN) for (sentence,_) in trainSet]\n",
    "    y_train = [label for (_,label) in trainSet]\n",
    "\n",
    "    mod = linear_model.LogisticRegression(C=reg_C, random_state=random_state)\n",
    "    mod.fit(X_train,y_train)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionarySizes = numpy.arange(start=100, stop=1501, step=100)\n",
    "reg_constants = numpy.arange(start=0.1, stop=1.51, step=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_bow_count = 0\n",
    "best_dict_size_bow_count = 0\n",
    "best_reg_bow_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_bow_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 0.7945390583137246, True)\n",
      "(200, 1, 0.797521142511008, True)\n",
      "(300, 1, 0.8024252731635719, True)\n",
      "(400, 1, 0.8087389045500082, True)\n",
      "(500, 1, 0.8129091629196468, True)\n",
      "(600, 1, 0.8159844372480954, True)\n",
      "(700, 1, 0.8206322950399553, True)\n",
      "(800, 1, 0.8220068494746406, True)\n",
      "(900, 1, 0.8229154532535005, True)\n",
      "(1000, 1, 0.8244996854833073, True)\n",
      "(1100, 1, 0.8262004053770706, True)\n",
      "(1200, 1, 0.8270041702583696, True)\n",
      "(1300, 1, 0.8280991542995597, True)\n",
      "(1400, 1, 0.8296134939309927, True)\n",
      "(1500, 1, 0.8302075810171703, True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for dictSize in dictionarySizes:\n",
    "#     for reg in reg_constants:\n",
    "#         acc = trainModelCounts(dictSize, reg, df_train, df_valid)\n",
    "#         if (acc > best_acc_bow_count):\n",
    "#             best_acc_bow_count = acc\n",
    "#             best_dict_size_bow_count = dictSize\n",
    "#             best_reg_bow_count = reg\n",
    "#         print((dictSize, reg, acc, acc > best_acc_bow_count))\n",
    "\n",
    "for dictSize in dictionarySizes:\n",
    "    (acc, model) = trainModelCounts(dictSize, 1, df_train, df_valid)\n",
    "    improved = False\n",
    "    if (acc > best_acc_bow_count):\n",
    "        improved = True\n",
    "        best_acc_bow_count = acc\n",
    "        best_dict_size_bow_count = dictSize\n",
    "        best_reg_bow_count = 1\n",
    "        best_model_bow_count = model\n",
    "    print((dictSize, best_reg_bow_count, acc, improved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 0.1, 0.8294717222901742, True)\n",
      "(1500, 0.2, 0.8302289009260877, True)\n",
      "(1500, 0.30000000000000004, 0.8302289009260877, False)\n",
      "(1500, 0.4, 0.8303453899469975, True)\n",
      "(1500, 0.5, 0.8303803366532704, True)\n",
      "(1500, 0.6, 0.8304735278699983, True)\n",
      "(1500, 0.7000000000000001, 0.8303919855553614, False)\n",
      "(1500, 0.8, 0.8305084745762712, True)\n",
      "(1500, 0.9, 0.8304269322616343, False)\n",
      "(1500, 1.0, 0.8304152833595434, False)\n",
      "(1500, 1.1, 0.8304618789679072, False)\n",
      "(1500, 1.2000000000000002, 0.8303803366532704, False)\n",
      "(1500, 1.3000000000000003, 0.8302405498281787, False)\n",
      "(1500, 1.4000000000000001, 0.8303104432407246, False)\n",
      "(1500, 1.5000000000000002, 0.8304152833595434, False)\n"
     ]
    }
   ],
   "source": [
    "for reg in reg_constants:\n",
    "    (acc, model) = trainModelCounts(best_dict_size_bow_count, reg, df_train, df_valid)\n",
    "    improved = False\n",
    "    if (acc > best_acc_bow_count):\n",
    "        improved = True\n",
    "        best_acc_bow_count = acc\n",
    "        best_dict_size_bow_count = best_dict_size_bow_count\n",
    "        best_reg_bow_count = reg\n",
    "        best_model_bow_count = model\n",
    "    print((best_dict_size_bow_count, reg, acc, improved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final hyperparameters\n",
    "best_dict_size_bow_count = 1500\n",
    "best_reg_bow_count = 0.8\n",
    "best_acc_bow_count = 0.8305084745762712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoWModel = trainModel_BoWPop(best_dict_size_bow_count, best_reg_bow_count, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "with open(\"bag_of_words_N_pop.pkl\", \"wb\") as f:\n",
    "    dump(BoWModel, f, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "BoWModel = joblib.load(\"bag_of_words_N_pop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run final model on test set\n",
    "wordsN = [x[1] for x in counts[:best_dict_size_bow_count]]\n",
    "wordIdN = dict(zip(wordsN, range(len(wordsN))))\n",
    "X_test = [featureCountN(sentence, wordsN, wordIdN) for (sentence,_) in df_test]\n",
    "y_test = [label for (_,label) in df_test]\n",
    "y_pred = BoWModel.predict(X_test)\n",
    "correct = y_pred == y_test\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16808078  0.11940327 -0.7997109  ... -0.17496671 -0.04581227\n",
      "  -0.5565175 ]]\n",
      "shithole\n",
      "sexist\n",
      "retard\n",
      "faggot\n",
      "idiot\n",
      "moron\n",
      "retarded\n",
      "nigger\n",
      "gays\n",
      "suck\n",
      "asshole\n",
      "muslims\n",
      "dickhead\n",
      "trans\n",
      "afro\n",
      "vagina\n",
      "blacks\n",
      "motherfucker\n",
      "immigrants\n",
      "kat\n",
      "pathetic\n",
      "buildthatwall\n",
      "douchebag\n",
      "fag\n",
      "idiots\n",
      "islam\n",
      "fool\n",
      "cock\n",
      "cunt\n",
      "loser\n",
      "f\n",
      "ti\n",
      "stupid\n",
      "indians\n",
      "jews\n",
      "chinese\n",
      "whore\n",
      "women\n",
      "trumpisatraitor\n",
      "liar\n",
      "peter\n",
      "dumb\n",
      "penis\n",
      "disabled\n",
      "ignorant\n",
      "jew\n",
      "dick\n",
      "illegal\n",
      "gay\n",
      "fuck\n"
     ]
    }
   ],
   "source": [
    "temp = BoWModel.coef_\n",
    "print(temp)\n",
    "numpy.argmax(temp)\n",
    "temp[:1,499]\n",
    "top10 = numpy.flip(numpy.argsort(temp)[0][-50:])\n",
    "for id in top10:\n",
    "    for (word, idx) in wordIdN.items():\n",
    "        if (id == idx):\n",
    "            print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8285631079270779\n",
      "Precision: 0.6630522902310498\n",
      "Recall: 0.3648173961527739\n",
      "F1 score: 0.47066863288134375\n",
      "Balanced Accuracy: 0.6579277674328882\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('Recall:', recall_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('F1 score:', f1_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('Balanced Accuracy:', balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285631079270779"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(correct) / len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train bag of words N highest TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(int)\n",
    "for (sentence, label) in df_train:\n",
    "    r = ''.join([c for c in sentence.lower() if not c in sp])\n",
    "    for w in set(r.split()):\n",
    "        df[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionarySizes = numpy.arange(start=500, stop=1501, step=100)\n",
    "reg_constants = numpy.arange(start=0.5, stop=1.51, step=0.1)\n",
    "\n",
    "def featureTFIDF_N(datum, wordsN, wordIdN):\n",
    "    feat = [0]*len(wordsN)\n",
    "    r = ''.join([c for c in datum.lower() if not c in sp])\n",
    "\n",
    "    tf = defaultdict(int)\n",
    "    for w in r.split():\n",
    "    # Note = rather than +=, different versions of tf could be used instead\n",
    "        tf[w] += 1\n",
    "    tfidf = dict(zip(wordsN,[tf[w] * math.log10(len(df_train) / df[w]) for w in wordsN]))\n",
    "    for w in wordsN:\n",
    "        feat[wordIdN[w]] = tfidf[w]\n",
    "    feat.append(1) # offset\n",
    "    return feat\n",
    "\n",
    "def trainModelTFIDF(dictSize, reg_C, trainSet, validSet):\n",
    "    wordsN = [x[1] for x in counts[:dictSize]]\n",
    "    wordIdN = dict(zip(wordsN, range(len(wordsN))))\n",
    "\n",
    "    X_train = [featureTFIDF_N(sentence, wordsN, wordIdN) for (sentence,_) in trainSet]\n",
    "    y_train = [label for (_,label) in trainSet]\n",
    "\n",
    "    X_valid = [featureTFIDF_N(sentence, wordsN, wordIdN) for (sentence,_) in validSet]\n",
    "    y_valid = [label for (_,label) in validSet]\n",
    "\n",
    "    mod = linear_model.LogisticRegression(C=reg_C, random_state=random_state)\n",
    "    mod.fit(X_train,y_train)\n",
    "    pred = mod.predict(X_valid)\n",
    "    correct = y_valid == pred\n",
    "    return (numpy.sum(correct) / len(correct), mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# best_acc_TFIDF = 0\n",
    "# best_dict_size_TFIDF = 0\n",
    "# best_reg_TFIDF = 0\n",
    "# best_model_TFIDF = 0\n",
    "\n",
    "dictionarySizes = numpy.arange(start=100, stop=1501, step=100)\n",
    "reg_constants = numpy.arange(start=0.1, stop=1.51, step=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7944691657153508, 100, 1, True)\n",
      "(0.7974861962118212, 200, 1, True)\n",
      "(0.8023670293315938, 300, 1, True)\n",
      "(0.8087622020827995, 400, 1, True)\n",
      "(0.812839270321273, 500, 1, True)\n",
      "(0.8159494909489086, 600, 1, True)\n",
      "(0.8206439438063509, 700, 1, True)\n",
      "(0.8219602544090581, 800, 1, True)\n",
      "(0.8231367798150175, 900, 1, True)\n",
      "(0.8245113342497029, 1000, 1, True)\n",
      "(0.8262702979754444, 1100, 1, True)\n",
      "(0.8269808727255784, 1200, 1, True)\n",
      "(0.8282738857954942, 1300, 1, True)\n",
      "(0.8295901963982014, 1400, 1, True)\n",
      "(0.8302425273163572, 1500, 1, True)\n",
      "(0.8300328495212357, 1500, 0.1, True)\n",
      "(0.8302308785499616, 1500, 0.2, True)\n",
      "(0.8302774736155442, 1500, 0.30000000000000004, True)\n",
      "(0.8302192297835659, 1500, 0.4, True)\n",
      "(0.8302541760827529, 1500, 0.5, True)\n"
     ]
    }
   ],
   "source": [
    "for dictSize in dictionarySizes:\n",
    "    acc, model = trainModelTFIDF(dictSize, 1, df_train, df_valid)\n",
    "    improved = False\n",
    "    if (acc > best_acc_TFIDF):\n",
    "        improved = True\n",
    "        best_acc_TFIDF = acc\n",
    "        best_dict_size_TFIDF = dictSize\n",
    "        best_model_TFIDF = model\n",
    "        best_reg_TFIDF = 1\n",
    "    print((acc, dictSize, 1, improved))\n",
    "\n",
    "for reg in reg_constants:\n",
    "    acc, model = trainModelTFIDF(best_dict_size_TFIDF, reg, df_train, df_valid)\n",
    "    improved = False\n",
    "    if (acc > best_acc_TFIDF):\n",
    "        improved = True\n",
    "        best_acc_TFIDF = acc\n",
    "        best_dict_size_TFIDF = best_dict_size_TFIDF\n",
    "        best_model_TFIDF = model\n",
    "        best_reg_TFIDF = reg\n",
    "    print((acc, best_dict_size_TFIDF, reg, improved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0.7944691657153508, 100, 1, True)\n",
    "(0.7974861962118212, 200, 1, True)\n",
    "(0.8023670293315938, 300, 1, True)\n",
    "(0.8087622020827995, 400, 1, True)\n",
    "(0.812839270321273, 500, 1, True)\n",
    "(0.8159494909489086, 600, 1, True)\n",
    "(0.8206439438063509, 700, 1, True)\n",
    "(0.8219602544090581, 800, 1, True)\n",
    "(0.8231367798150175, 900, 1, True)\n",
    "(0.8245113342497029, 1000, 1, True)\n",
    "(0.8262702979754444, 1100, 1, True)\n",
    "(0.8269808727255784, 1200, 1, True)\n",
    "(0.8282738857954942, 1300, 1, True)\n",
    "(0.8295901963982014, 1400, 1, True)\n",
    "(0.8302425273163572, 1500, 1, True)\n",
    "(0.8300328495212357, 1500, 0.1, True)\n",
    "(0.8302308785499616, 1500, 0.2, True)\n",
    "(0.8302774736155442, 1500, 0.30000000000000004, True)\n",
    "(0.8302192297835659, 1500, 0.4, True)\n",
    "(0.8302541760827529, 1500, 0.5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8303453899469975, 1500, 0.5, True)\n",
      "(0.8303686877511794, 1500, 0.6, True)\n",
      "(0.8303919855553614, 1500, 0.7, True)\n",
      "(0.8303919855553614, 1500, 0.7999999999999999, False)\n"
     ]
    }
   ],
   "source": [
    "for reg in reg_constants:\n",
    "    acc, model = trainModelTFIDF(best_dict_size_TFIDF, reg, df_train, df_valid)\n",
    "    improved = False\n",
    "    if (acc > best_acc_TFIDF):\n",
    "        improved = True\n",
    "        best_acc_TFIDF = acc\n",
    "        best_dict_size_TFIDF = best_dict_size_TFIDF\n",
    "        best_model_TFIDF = model\n",
    "        best_reg_TFIDF = reg\n",
    "    print((acc, best_dict_size_TFIDF, reg, improved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8304851767720892, 1500, 0.1, True)\n",
      "(0.8304502300658163, 1500, 0.2, False)\n",
      "(0.8303220921428155, 1500, 0.3, False)\n",
      "(0.8303220921428155, 1500, 0.4, False)\n",
      "(0.8304036344574524, 1500, 0.9, False)\n",
      "(0.8304269322616343, 1500, 1.0, False)\n",
      "(0.8304502300658163, 1500, 1.1, False)\n",
      "(0.8304618789679072, 1500, 1.2, False)\n",
      "(0.8304618789679072, 1500, 1.3, False)\n",
      "(0.8304618789679072, 1500, 1.4, False)\n",
      "(0.8304735278699983, 1500, 1.5, False)\n"
     ]
    }
   ],
   "source": [
    "for reg in [0.1, 0.2, 0.3, 0.4, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]:\n",
    "    acc, model = trainModelTFIDF(best_dict_size_TFIDF, reg, df_train, df_valid)\n",
    "    improved = False\n",
    "    if (acc > best_acc_TFIDF):\n",
    "        improved = True\n",
    "        best_acc_TFIDF = acc\n",
    "        best_dict_size_TFIDF = best_dict_size_TFIDF\n",
    "        best_model_TFIDF = model\n",
    "        best_reg_TFIDF = reg\n",
    "    print((acc, best_dict_size_TFIDF, reg, improved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final TFIDF hyperparameters\n",
    "best_dict_size_TFIDF = 1500\n",
    "best_reg_TFIDF = 0.1\n",
    "best_acc_TFIDF = 0.8304851767720892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "with open(\"bag_of_words_N_TFIDF.pkl\", \"wb\") as f:\n",
    "    dump(best_model_TFIDF, f, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "best_model_TFIDF = joblib.load(\"bag_of_words_N_TFIDF.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14856483  0.10127752 -0.62906417 ... -0.06073759 -0.01532128\n",
      "  -0.02071973]]\n",
      "sexist\n",
      "shithole\n",
      "retard\n",
      "faggot\n",
      "idiot\n",
      "retarded\n",
      "nigger\n",
      "moron\n",
      "suck\n",
      "muslims\n",
      "vagina\n",
      "asshole\n",
      "gays\n",
      "trans\n",
      "immigrants\n",
      "blacks\n",
      "women\n",
      "kat\n",
      "fuck\n",
      "afro\n",
      "stupid\n",
      "dickhead\n",
      "islam\n",
      "motherfucker\n",
      "pathetic\n",
      "buildthatwall\n",
      "fag\n",
      "black\n",
      "jews\n",
      "idiots\n",
      "douchebag\n",
      "f\n",
      "cunt\n",
      "cock\n",
      "fool\n",
      "chinese\n",
      "penis\n",
      "loser\n",
      "gay\n",
      "dumb\n",
      "ti\n",
      "whore\n",
      "trumpisatraitor\n",
      "indians\n",
      "illegal\n",
      "liar\n",
      "muslim\n",
      "fucking\n",
      "disabled\n",
      "peter\n"
     ]
    }
   ],
   "source": [
    "temp = best_model_TFIDF.coef_\n",
    "print(temp)\n",
    "numpy.argmax(temp)\n",
    "temp[:1,499]\n",
    "top10 = numpy.flip(numpy.argsort(temp)[0][-50:])\n",
    "for id in top10:\n",
    "    for (word, idx) in wordIdN.items():\n",
    "        if (id == idx):\n",
    "            print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run final model on test set\n",
    "wordsN = [x[1] for x in counts[:best_dict_size_TFIDF]]\n",
    "wordIdN = dict(zip(wordsN, range(len(wordsN))))\n",
    "X_test = [featureTFIDF_N(sentence, wordsN, wordIdN) for (sentence,_) in df_test]\n",
    "y_test = [label for (_,label) in df_test]\n",
    "y_pred = best_model_TFIDF.predict(X_test)\n",
    "correct = y_pred == y_test\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.828528161220805\n",
      "Precision: 0.6634801179701006\n",
      "Recall: 0.363758015054363\n",
      "F1 score: 0.46989340247767225\n",
      "Balanced Accuracy: 0.6575158798582079\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('Recall:', recall_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('F1 score:', f1_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('Balanced Accuracy:', balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.828528161220805"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(correct) / len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceTokens = []\n",
    "punctuation = set(string.punctuation)\n",
    "for (sentence,label) in df_train:\n",
    "    r = ''.join([c for c in sentence.lower() if not c in punctuation])\n",
    "    tokens = []\n",
    "    for w in r.split():\n",
    "        tokens.append(w)\n",
    "    sentenceTokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count_list = numpy.arange(start=1, stop=21, step=1)\n",
    "vector_size_list = numpy.arange(start=5, stop=156, step=5)\n",
    "window_list = numpy.arange(start=1, stop=21, step=1)\n",
    "alpha_list = numpy.arange(start=0.001, stop=0.03, step=0.001)\n",
    "negative_list = numpy.arange(start=1, stop=21, step=1)\n",
    "hs_list = numpy.arange(start=0, stop=2, step=1)\n",
    "sg_list = numpy.arange(start=0, stop=2, step=1)\n",
    "reg_list = numpy.arange(start=0.1, stop=1.51, step=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector_size_logistic = 100\n",
    "best_min_count_logistic = 2\n",
    "best_window_logistic = 3\n",
    "best_alpha_logistic = 0.01\n",
    "best_negative_logistic = 5\n",
    "best_hs_logistic = 1\n",
    "best_sg_logistic = 1\n",
    "best_reg_logistic = 1\n",
    "best_acc_logistic = 0\n",
    "best_w2v_model = 0\n",
    "best_w2v_logistic_model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence, model, vector_size):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return numpy.zeros(vector_size)\n",
    "    words_vecs = numpy.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7832372298910828, 5, True)\n",
      "(0.7951307589259712, 10, True)\n",
      "(0.7982526646863534, 15, True)\n",
      "(0.8002562758460016, 20, True)\n",
      "(0.8012930281320986, 25, True)\n",
      "(0.8050789213116664, 30, True)\n",
      "(0.8059409400663987, 35, True)\n",
      "(0.8059758867726716, 40, True)\n",
      "(0.8080610402469567, 45, True)\n",
      "(0.8082124759741395, 50, True)\n",
      "(0.8093307705748733, 55, True)\n",
      "(0.8106354476090628, 60, True)\n",
      "(0.8097734288543305, 65, False)\n",
      "(0.8106703943153358, 70, True)\n",
      "(0.8116954976993418, 75, True)\n",
      "(0.8127089521812569, 80, True)\n",
      "(0.812138155978799, 85, False)\n",
      "(0.8122895917059817, 90, False)\n",
      "(0.8135127264255344, 95, True)\n",
      "(0.8127904944958938, 100, False)\n",
      "(0.8125342186498923, 105, False)\n",
      "(0.8134428330129885, 110, False)\n",
      "(0.8133263439920787, 115, False)\n",
      "(0.8145611276137225, 120, True)\n",
      "(0.8140602248238104, 125, False)\n",
      "(0.8151668705224533, 130, True)\n",
      "(0.8153299551517269, 135, True)\n",
      "(0.8153881996621818, 140, True)\n",
      "(0.8163900052420059, 145, True)\n",
      "(0.8152367639349991, 150, False)\n",
      "(0.8157842623332751, 155, False)\n",
      "(0.8159822936688217, 1, False)\n",
      "(0.8164133030461879, 2, True)\n",
      "(0.8153649018579999, 3, False)\n",
      "(0.8150270836973615, 4, False)\n",
      "(0.8157842623332751, 5, False)\n",
      "(0.8159007513541848, 6, False)\n",
      "(0.8155745820956375, 7, False)\n",
      "(0.8160405381792766, 8, False)\n",
      "(0.8165530898712796, 9, True)\n",
      "(0.8160172403750946, 10, False)\n",
      "(0.8151901683266353, 11, False)\n",
      "(0.8140369270196284, 12, False)\n",
      "(0.8154347952705457, 13, False)\n",
      "(0.816331760731551, 14, False)\n",
      "(0.8139437358029006, 15, False)\n",
      "(0.815295008445454, 16, False)\n",
      "(0.814747510047178, 17, False)\n",
      "(0.8154930397810006, 18, False)\n",
      "(0.8153532529559089, 19, False)\n",
      "(0.8155163375851826, 20, False)\n",
      "(0.811625604286796, 1, False)\n",
      "(0.8143397984739938, 2, False)\n",
      "(0.8159356980604578, 3, False)\n",
      "(0.8162618673190052, 4, False)\n",
      "(0.8169142058361, 5, True)\n",
      "(0.8168326635214631, 6, False)\n",
      "(0.8169840992486458, 7, True)\n",
      "(0.8175199487448308, 8, True)\n",
      "(0.8172170772904653, 9, False)\n",
      "(0.8175199487448308, 10, False)\n",
      "(0.8187081367581105, 11, True)\n",
      "(0.8172520239967384, 12, False)\n",
      "(0.8181955850661076, 13, False)\n",
      "(0.8175665443531948, 14, False)\n",
      "(0.8186032966392918, 15, False)\n",
      "(0.8179160114159241, 16, False)\n",
      "(0.8179626070242879, 17, False)\n",
      "(0.817950958122197, 18, False)\n",
      "(0.8180441493389248, 19, False)\n",
      "(0.8188712213873842, 20, True)\n",
      "(0.8079678490302289, 0.001, False)\n",
      "(0.8136641621527171, 0.002, False)\n",
      "(0.8166812277942804, 0.003, False)\n",
      "(0.8169608014444638, 0.004, False)\n",
      "(0.8175315976469217, 0.005, False)\n",
      "(0.8171355349758286, 0.006, False)\n",
      "(0.8179626070242879, 0.007, False)\n",
      "(0.8184984565204729, 0.008, False)\n",
      "(0.8177878734929233, 0.009000000000000001, False)\n",
      "(0.8180557982410158, 0.010000000000000002, False)\n",
      "(0.8187663812685655, 0.011, False)\n",
      "(0.8183470207932902, 0.012, False)\n",
      "(0.817927660318015, 0.013000000000000001, False)\n",
      "(0.8188712213873842, 0.014000000000000002, False)\n",
      "(0.8178927136117421, 0.015, False)\n",
      "(0.817974255926379, 0.016, False)\n",
      "(0.8177645756887414, 0.017, False)\n",
      "(0.8181023938493797, 0.018000000000000002, False)\n",
      "(0.818486807618382, 0.019000000000000003, False)\n",
      "(0.8178228201991963, 0.02, False)\n",
      "(0.8170306948570097, 0.021, False)\n",
      "(0.8172986196051022, 0.022000000000000002, False)\n",
      "(0.8177412778845594, 0.023, False)\n",
      "(0.8176480866678315, 0.024, False)\n",
      "(0.8172170772904653, 0.025, False)\n",
      "(0.8159124002562759, 0.026000000000000002, False)\n",
      "(0.8172986196051022, 0.027000000000000003, False)\n",
      "(0.8169491525423729, 0.028, False)\n",
      "(0.8164366008503698, 0.029, False)\n",
      "(0.8177529267866503, 1, False)\n",
      "(0.8180674471431068, 2, False)\n",
      "(0.8183120740870173, 3, False)\n",
      "(0.8183004251849263, 4, False)\n",
      "(0.8179859048284699, 5, False)\n",
      "(0.8185217543246549, 6, False)\n",
      "(0.8179975537305609, 7, False)\n",
      "(0.8177179800803774, 8, False)\n",
      "(0.8186149455413827, 9, False)\n",
      "(0.8185799988351098, 10, False)\n",
      "(0.8189178169957482, 11, True)\n",
      "(0.8187081367581105, 12, False)\n",
      "(0.8183120740870173, 13, False)\n",
      "(0.8181839361640165, 14, False)\n",
      "(0.8174966509406488, 15, False)\n",
      "(0.8182538295765625, 16, False)\n",
      "(0.8185683499330189, 17, False)\n",
      "(0.8183703185974722, 18, False)\n",
      "(0.8173685130176481, 19, False)\n",
      "(0.8184518609121091, 20, False)\n",
      "(0.8167860679130992, 0, False)\n",
      "(0.8185217543246549, 1, False)\n",
      "(0.8091676859455996, 0, False)\n",
      "(0.8189178169957482, 1, False)\n",
      "(0.8175432465490128, 0.1, False)\n",
      "(0.8175665443531948, 0.2, False)\n",
      "(0.8181606383598345, 0.30000000000000004, False)\n",
      "(0.8186265944434737, 0.4, False)\n",
      "(0.8181955850661076, 0.5, False)\n",
      "(0.8188013279748384, 0.6, False)\n",
      "(0.8186032966392918, 0.7000000000000001, False)\n",
      "(0.8181023938493797, 0.8, False)\n",
      "(0.8186149455413827, 0.9, False)\n",
      "(0.8186382433455647, 1.0, False)\n",
      "(0.8181955850661076, 1.1, False)\n",
      "(0.8183120740870173, 1.2000000000000002, False)\n",
      "(0.8187780301706564, 1.3000000000000003, False)\n",
      "(0.8175315976469217, 1.4000000000000001, False)\n",
      "(0.8191158483312948, 1.5000000000000002, True)\n"
     ]
    }
   ],
   "source": [
    "for val in vector_size_list:\n",
    "    w2v = Word2Vec(sentenceTokens,\n",
    "                 min_count=best_min_count_logistic, # Words/items with fewer instances are discarded\n",
    "                 vector_size=val, # Model dimensionality\n",
    "                 window=best_window_logistic, # Window size\n",
    "                 workers=4,\n",
    "                 seed=random_state,\n",
    "                 alpha=best_alpha_logistic,\n",
    "                 negative=best_negative_logistic,\n",
    "                 ns_exponent=0.75,\n",
    "                 hs=best_hs_logistic,\n",
    "                 sg=best_sg_logistic) # Skip-gram model\n",
    "    # vectorize sentence data based on new w2v model\n",
    "    X_train = numpy.array([vectorize(sentence,w2v,val) for (sentence,_ ) in df_train])\n",
    "    X_valid = numpy.array([vectorize(sentence,w2v,val) for (sentence,_) in df_valid])\n",
    "    logisticModel = linear_model.LogisticRegression(C=best_reg_logistic, random_state=random_state)\n",
    "    logisticModel.fit(X_train, df_train[:,1])\n",
    "    y_pred = logisticModel.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_logistic):\n",
    "        improved = True\n",
    "        best_acc_logistic = acc\n",
    "        best_vector_size_logistic = val\n",
    "        best_w2v_model = w2v\n",
    "        best_w2v_logistic_model = logisticModel\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for val in min_count_list:\n",
    "    w2v = Word2Vec(sentenceTokens,\n",
    "                 min_count=val, # Words/items with fewer instances are discarded\n",
    "                 vector_size=best_vector_size_logistic, # Model dimensionality\n",
    "                 window=best_window_logistic, # Window size\n",
    "                 workers=4,\n",
    "                 seed=random_state,\n",
    "                 alpha=best_alpha_logistic,\n",
    "                 negative=best_negative_logistic,\n",
    "                 ns_exponent=0.75,\n",
    "                 hs=best_hs_logistic,\n",
    "                 sg=best_sg_logistic) # Skip-gram model\n",
    "    # vectorize sentence data based on new w2v model\n",
    "    X_train = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_ ) in df_train])\n",
    "    X_valid = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_) in df_valid])\n",
    "    logisticModel = linear_model.LogisticRegression(C=best_reg_logistic, random_state=random_state)\n",
    "    logisticModel.fit(X_train, df_train[:,1])\n",
    "    y_pred = logisticModel.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_logistic):\n",
    "        improved = True\n",
    "        best_acc_logistic = acc\n",
    "        best_min_count_logistic = val\n",
    "        best_w2v_model = w2v\n",
    "        best_w2v_logistic_model = logisticModel\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for val in window_list:\n",
    "    w2v = Word2Vec(sentenceTokens,\n",
    "                 min_count=best_min_count_logistic, # Words/items with fewer instances are discarded\n",
    "                 vector_size=best_vector_size_logistic, # Model dimensionality\n",
    "                 window=val, # Window size\n",
    "                 workers=4,\n",
    "                 seed=random_state,\n",
    "                 alpha=best_alpha_logistic,\n",
    "                 negative=best_negative_logistic,\n",
    "                 ns_exponent=0.75,\n",
    "                 hs=best_hs_logistic,\n",
    "                 sg=best_sg_logistic) # Skip-gram model\n",
    "    # vectorize sentence data based on new w2v model\n",
    "    X_train = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_ ) in df_train])\n",
    "    X_valid = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_) in df_valid])\n",
    "    logisticModel = linear_model.LogisticRegression(C=best_reg_logistic, random_state=random_state)\n",
    "    logisticModel.fit(X_train, df_train[:,1])\n",
    "    y_pred = logisticModel.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_logistic):\n",
    "        improved = True\n",
    "        best_acc_logistic = acc\n",
    "        best_window_logistic = val\n",
    "        best_w2v_model = w2v\n",
    "        best_w2v_logistic_model = logisticModel\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for val in alpha_list:\n",
    "    w2v = Word2Vec(sentenceTokens,\n",
    "                 min_count=best_min_count_logistic, # Words/items with fewer instances are discarded\n",
    "                 vector_size=best_vector_size_logistic, # Model dimensionality\n",
    "                 window=best_window_logistic, # Window size\n",
    "                 workers=4,\n",
    "                 seed=random_state,\n",
    "                 alpha=val,\n",
    "                 negative=best_negative_logistic,\n",
    "                 ns_exponent=0.75,\n",
    "                 hs=best_hs_logistic,\n",
    "                 sg=best_sg_logistic) # Skip-gram model\n",
    "    # vectorize sentence data based on new w2v model\n",
    "    X_train = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_ ) in df_train])\n",
    "    X_valid = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_) in df_valid])\n",
    "    logisticModel = linear_model.LogisticRegression(C=best_reg_logistic, random_state=random_state)\n",
    "    logisticModel.fit(X_train, df_train[:,1])\n",
    "    y_pred = logisticModel.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_logistic):\n",
    "        improved = True\n",
    "        best_acc_logistic = acc\n",
    "        best_alpha_logistic = val\n",
    "        best_w2v_model = w2v\n",
    "        best_w2v_logistic_model = logisticModel\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for val in negative_list:\n",
    "    w2v = Word2Vec(sentenceTokens,\n",
    "                 min_count=best_min_count_logistic, # Words/items with fewer instances are discarded\n",
    "                 vector_size=best_vector_size_logistic, # Model dimensionality\n",
    "                 window=best_window_logistic, # Window size\n",
    "                 workers=4,\n",
    "                 seed=random_state,\n",
    "                 alpha=best_alpha_logistic,\n",
    "                 negative=val,\n",
    "                 ns_exponent=0.75,\n",
    "                 hs=best_hs_logistic,\n",
    "                 sg=best_sg_logistic) # Skip-gram model\n",
    "    # vectorize sentence data based on new w2v model\n",
    "    X_train = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_ ) in df_train])\n",
    "    X_valid = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_) in df_valid])\n",
    "    logisticModel = linear_model.LogisticRegression(C=best_reg_logistic, random_state=random_state)\n",
    "    logisticModel.fit(X_train, df_train[:,1])\n",
    "    y_pred = logisticModel.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_logistic):\n",
    "        improved = True\n",
    "        best_acc_logistic = acc\n",
    "        best_negative_logistic = val\n",
    "        best_w2v_model = w2v\n",
    "        best_w2v_logistic_model = logisticModel\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for val in hs_list:\n",
    "    w2v = Word2Vec(sentenceTokens,\n",
    "                 min_count=best_min_count_logistic, # Words/items with fewer instances are discarded\n",
    "                 vector_size=best_vector_size_logistic, # Model dimensionality\n",
    "                 window=best_window_logistic, # Window size\n",
    "                 workers=4,\n",
    "                 seed=random_state,\n",
    "                 alpha=best_alpha_logistic,\n",
    "                 negative=best_negative_logistic,\n",
    "                 ns_exponent=0.75,\n",
    "                 hs=val,\n",
    "                 sg=best_sg_logistic) # Skip-gram model\n",
    "    # vectorize sentence data based on new w2v model\n",
    "    X_train = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_ ) in df_train])\n",
    "    X_valid = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_) in df_valid])\n",
    "    logisticModel = linear_model.LogisticRegression(C=best_reg_logistic, random_state=random_state)\n",
    "    logisticModel.fit(X_train, df_train[:,1])\n",
    "    y_pred = logisticModel.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_logistic):\n",
    "        improved = True\n",
    "        best_acc_logistic = acc\n",
    "        best_hs_logistic = val\n",
    "        best_w2v_model = w2v\n",
    "        best_w2v_logistic_model = logisticModel\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for val in sg_list:\n",
    "    w2v = Word2Vec(sentenceTokens,\n",
    "                 min_count=best_min_count_logistic, # Words/items with fewer instances are discarded\n",
    "                 vector_size=best_vector_size_logistic, # Model dimensionality\n",
    "                 window=best_window_logistic, # Window size\n",
    "                 workers=4,\n",
    "                 seed=random_state,\n",
    "                 alpha=best_alpha_logistic,\n",
    "                 negative=best_negative_logistic,\n",
    "                 ns_exponent=0.75,\n",
    "                 hs=best_hs_logistic,\n",
    "                 sg=val) # Skip-gram model\n",
    "    # vectorize sentence data based on new w2v model\n",
    "    X_train = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_ ) in df_train])\n",
    "    X_valid = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_) in df_valid])\n",
    "    logisticModel = linear_model.LogisticRegression(C=best_reg_logistic, random_state=random_state)\n",
    "    logisticModel.fit(X_train, df_train[:,1])\n",
    "    y_pred = logisticModel.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_logistic):\n",
    "        improved = True\n",
    "        best_acc_logistic = acc\n",
    "        best_sg_logistic = val\n",
    "        best_w2v_model = w2v\n",
    "        best_w2v_logistic_model = logisticModel\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for reg in reg_list:\n",
    "    w2v = Word2Vec(sentenceTokens,\n",
    "                 min_count=best_min_count_logistic, # Words/items with fewer instances are discarded\n",
    "                 vector_size=best_vector_size_logistic, # Model dimensionality\n",
    "                 window=best_window_logistic, # Window size\n",
    "                 workers=4,\n",
    "                 seed=random_state,\n",
    "                 alpha=best_alpha_logistic,\n",
    "                 negative=best_negative_logistic,\n",
    "                 ns_exponent=0.75,\n",
    "                 hs=best_hs_logistic,\n",
    "                 sg=best_sg_logistic) # Skip-gram model\n",
    "    # vectorize sentence data based on new w2v model\n",
    "    X_train = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_ ) in df_train])\n",
    "    X_valid = numpy.array([vectorize(sentence,w2v,best_vector_size_logistic) for (sentence,_) in df_valid])\n",
    "    logisticModel = linear_model.LogisticRegression(C=reg, random_state=random_state)\n",
    "    logisticModel.fit(X_train, df_train[:,1])\n",
    "    y_pred = logisticModel.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_logistic):\n",
    "        improved = True\n",
    "        best_acc_logistic = acc\n",
    "        best_reg_logistic = reg\n",
    "        best_w2v_model = w2v\n",
    "        best_w2v_logistic_model = logisticModel\n",
    "    print((acc, reg, improved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final w2v + logistic c hyperparameters\n",
    "best_vector_size_logistic = 145\n",
    "best_min_count_logistic = 9\n",
    "best_window_logistic = 20\n",
    "best_alpha_logistic = 0.014\n",
    "best_negative_logistic = 11\n",
    "best_hs_logistic = 1\n",
    "best_sg_logistic = 1\n",
    "best_reg_logistic = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_w2v_model = w2v\n",
    "best_w2v_logistic_model = logisticModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8169025569340089\n",
      "Precision: 0.6208701341184167\n",
      "Recall: 0.3174797881237803\n",
      "F1 score: 0.4201283848594407\n",
      "Balanced Accuracy: 0.633139835160403\n"
     ]
    }
   ],
   "source": [
    "x_test = numpy.array([vectorize(sentence, best_w2v_model, best_vector_size_logistic) for (sentence,_) in df_test])\n",
    "y_pred = best_w2v_logistic_model.predict(x_test)\n",
    "y_test = df_test[:,1]\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('Recall:', recall_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('F1 score:', f1_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('Balanced Accuracy:', balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "best_w2v_model.save(\"w2v.model\")\n",
    "with open(\"w2v_logistic.pkl\", \"wb\") as f:\n",
    "    dump(best_w2v_logistic_model, f, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "best_w2v_model = Word2Vec.load(\"w2v.model\")\n",
    "best_w2v_logistic_model = joblib.load(\"w2v_logistic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "best_w2v_model.wv.save(\"w2v.wordvectors\")\n",
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv = KeyedVectors.load(\"w2v.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.96327674e-01, -2.64048467e-01, -1.06107247e+00,\n",
       "        -1.87242300e+00, -1.41985430e+00, -7.38436365e-01,\n",
       "         6.84935197e-01,  1.18076460e+00,  7.38430814e-02,\n",
       "         2.46263773e+00,  1.14372662e-01,  9.59354400e-01,\n",
       "        -4.96846665e-01,  4.94514787e-01, -3.48704908e-01,\n",
       "         5.51597319e-02,  4.86208804e-01,  6.28021781e-01,\n",
       "        -1.05293638e+00,  6.38402104e-01, -6.71534753e-01,\n",
       "         6.06007558e-01,  3.55717367e-01, -7.66201517e-01,\n",
       "         7.09018950e-01, -1.26117965e+00, -3.14915035e-01,\n",
       "        -4.10862078e-01,  1.24602200e+00,  7.19441029e-01,\n",
       "        -1.66522955e+00, -2.41011278e-01, -3.49482457e-01,\n",
       "         4.13693904e-01, -2.07794997e+00, -7.40472047e-01,\n",
       "        -8.42232007e-01,  5.70355538e-01,  1.04943857e+00,\n",
       "        -5.21434623e-01, -1.31552645e+00,  1.96348972e-01,\n",
       "         2.30759508e-01,  1.27910822e+00,  2.79399944e-01,\n",
       "         7.27688162e-01, -2.26950605e-01, -6.03042101e-01,\n",
       "         1.72676730e+00,  1.45011667e-01,  9.96244045e-02,\n",
       "        -5.79706983e-01, -1.67476093e+00,  3.46848499e-02,\n",
       "        -5.33014025e-01, -3.24638205e-01,  7.31056584e-01,\n",
       "         8.32888550e-01,  1.85391098e+00,  2.32362430e-03,\n",
       "        -3.01917615e+00, -7.71016611e-01, -1.18657286e-01,\n",
       "        -8.57768400e-01, -9.09601885e-03, -2.13390216e-01,\n",
       "        -1.66805285e-01, -4.46551706e-01,  6.57160792e-02,\n",
       "        -4.18140180e-01,  3.27162936e-01, -2.67637284e+00,\n",
       "         9.21686413e-01, -6.81065389e-02, -8.36570791e-01,\n",
       "         1.88932803e+00,  8.87604521e-01,  2.84786749e-01,\n",
       "        -3.05534085e-01, -1.57821208e+00, -2.74374402e-01,\n",
       "         5.05724235e-01,  1.06965298e+00,  9.41716693e-02,\n",
       "         6.68865215e-01, -3.48646583e-01,  1.14648322e+00,\n",
       "         2.13919883e+00, -8.00985846e-02, -2.50842031e-01,\n",
       "         6.27291146e-02,  1.01648003e+00,  1.52231155e-01,\n",
       "        -4.08082486e-01, -1.35344572e+00,  7.40436020e-01,\n",
       "        -6.86379990e-01, -1.72353461e-01, -9.30261448e-01,\n",
       "         5.46101258e-01,  1.36343144e-01, -9.40297008e-01,\n",
       "         5.92407259e-01,  8.03296969e-01,  1.34072440e+00,\n",
       "        -6.44774554e-01, -1.91568206e-01,  1.00188387e+00,\n",
       "         4.85868862e-01,  1.03357379e+00,  1.32303976e+00,\n",
       "         7.54598556e-01, -1.75674108e+00,  5.53701358e-01,\n",
       "        -1.31862913e+00, -2.89111593e-01,  1.19086163e+00,\n",
       "        -1.15217931e+00, -5.10503712e-01, -7.94815673e-01,\n",
       "         1.78110968e+00, -4.12110262e-01, -2.87129857e-01,\n",
       "        -1.33477262e-01, -9.91660806e-01, -7.17822723e-01,\n",
       "        -9.44159715e-01, -5.69725002e-01,  7.57908067e-01,\n",
       "         2.51742238e-01, -7.55809216e-01, -8.22860702e-02,\n",
       "         8.89370233e-01,  1.37026534e+00, -1.78904083e+00,\n",
       "        -5.18675187e-01,  1.31315155e+00, -1.37202163e+00,\n",
       "         1.27514268e+00,  2.21701880e-01, -6.85912612e-01,\n",
       "         2.00653074e+00,  1.67963867e+00,  7.89415328e-02,\n",
       "        -4.42851229e-01]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_w2v_logistic_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16383345,  0.00369521, -0.00308481, ...,  0.01558352,\n",
       "         0.03043194, -0.16564284],\n",
       "       [ 0.39454067, -0.17457217, -0.16327918, ...,  0.00400706,\n",
       "         0.08104239, -0.08968896],\n",
       "       [-0.00546203,  0.10912228, -0.05407842, ..., -0.06179465,\n",
       "        -0.01703835, -0.11920708],\n",
       "       ...,\n",
       "       [-0.13001303, -0.04955123, -0.13867822, ...,  0.05475272,\n",
       "        -0.05555829,  0.12960625],\n",
       "       [-0.15998366, -0.04628295, -0.34527305, ..., -0.07891646,\n",
       "        -0.21827246,  0.17036958],\n",
       "       [-0.2098744 , -0.01413845, -0.14432538, ..., -0.00093756,\n",
       "        -0.00109505,  0.13244289]], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = numpy.array([vectorize(sentence,best_w2v_model,best_vector_size_logistic) for (sentence,_ ) in df_train])\n",
    "X_valid = numpy.array([vectorize(sentence,best_w2v_model,best_vector_size_logistic) for (sentence,_) in df_valid])\n",
    "X_test = numpy.array([vectorize(sentence,best_w2v_model,best_vector_size_logistic) for (sentence,_) in df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_list = numpy.arange(start=1, stop=4, step=1)\n",
    "min_samples_split_list = numpy.arange(start=2, stop=6, step=1)\n",
    "n_estimators_list = numpy.arange(start=5, stop=96, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_depth = 1\n",
    "best_min_samples_split = 2\n",
    "best_n_estimators = 20\n",
    "best_acc_Ada = 0\n",
    "best_model_Ada = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8055914730036694, 1, True)\n",
      "(0.8123245384122546, 2, True)\n",
      "(0.8158425068437299, 3, True)\n",
      "(0.8158425068437299, 2, False)\n",
      "(0.8158425068437299, 3, False)\n",
      "(0.8158425068437299, 4, False)\n",
      "(0.8158425068437299, 5, False)\n",
      "(0.7906575805230357, 5, False)\n",
      "(0.8140369270196284, 15, False)\n",
      "(0.8176247888636496, 25, True)\n",
      "(0.8193022307647504, 35, True)\n",
      "(0.8203389830508474, 45, True)\n",
      "(0.822668763469043, 55, True)\n",
      "(0.8241365251325062, 65, True)\n",
      "(0.8253014153416041, 75, True)\n",
      "(0.8251732774186032, 85, False)\n",
      "(0.825324713145786, 95, True)\n"
     ]
    }
   ],
   "source": [
    "for val in max_depth_list:\n",
    "    bdt = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=val, min_samples_split=best_min_samples_split, random_state=random_state), algorithm=\"SAMME\", n_estimators=best_n_estimators, random_state=random_state\n",
    "    )\n",
    "\n",
    "    bdt.fit(X_train, df_train[:,1])\n",
    "    y_pred = bdt.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_Ada):\n",
    "        improved = True\n",
    "        best_acc_Ada = acc\n",
    "        best_max_depth = val\n",
    "        best_model_Ada = bdt\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for val in min_samples_split_list:\n",
    "    bdt = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=val, random_state=random_state), algorithm=\"SAMME\", n_estimators=best_n_estimators, random_state=random_state\n",
    "    )\n",
    "\n",
    "    bdt.fit(X_train, df_train[:,1])\n",
    "    y_pred = bdt.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_Ada):\n",
    "        improved = True\n",
    "        best_acc_Ada = acc\n",
    "        best_min_samples_split = val\n",
    "        best_model_Ada = bdt\n",
    "    print((acc, val, improved))\n",
    "\n",
    "for val in n_estimators_list:\n",
    "    bdt = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split, random_state=random_state), algorithm=\"SAMME\", n_estimators=val, random_state=random_state\n",
    "    )\n",
    "\n",
    "    bdt.fit(X_train, df_train[:,1])\n",
    "    y_pred = bdt.predict(X_valid)\n",
    "    acc = accuracy_score(df_valid[:,1], y_pred)\n",
    "    improved = False\n",
    "    if (acc > best_acc_Ada):\n",
    "        improved = True\n",
    "        best_acc_Ada = acc\n",
    "        best_n_estimators = val\n",
    "        best_model_Ada = bdt\n",
    "    print((acc, val, improved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8239967383074145\n",
      "Precision: 0.5981113734203582\n",
      "Recall: 0.4802899358795651\n",
      "F1 score: 0.5327643256950243\n",
      "Balanced Accuracy: 0.6975297419053251\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model_Ada.predict(X_test)\n",
    "y_test = df_test[:,1]\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('Recall:', recall_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('F1 score:', f1_score(y_test, y_pred, pos_label=\"1\"))\n",
    "print('Balanced Accuracy:', balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "with open(\"w2vAda.pkl\", \"wb\") as f:\n",
    "    dump(best_model_Ada, f, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "best_model_Ada = joblib.load(\"w2vAda.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0061376 , -0.07512499, -0.102892  , -0.10697171,  0.09760675,\n",
       "        0.07567528, -0.0439553 , -0.11647027,  0.13137282, -0.05433286,\n",
       "       -0.03408767,  0.09743832,  0.0212919 , -0.09305374, -0.03200231,\n",
       "       -0.12972896, -0.11462268, -0.09031932, -0.07269812, -0.0032609 ,\n",
       "        0.00795485,  0.21384385, -0.13057181,  0.04971723, -0.13659781,\n",
       "       -0.09448126, -0.12347023,  0.15113014,  0.18624619,  0.02180492,\n",
       "        0.04764103, -0.08936383, -0.08834337,  0.03167488,  0.13145435,\n",
       "        0.12821089, -0.10400044, -0.0064697 , -0.01404202, -0.11454906,\n",
       "        0.04297676, -0.02179311,  0.03081575, -0.22197857, -0.18095525,\n",
       "       -0.13829835,  0.07527985,  0.17718308,  0.15352491, -0.015457  ,\n",
       "       -0.08008385, -0.18507148, -0.20820385,  0.06330244,  0.01450803,\n",
       "       -0.24304129, -0.03827763, -0.06023232,  0.09262066, -0.09505969,\n",
       "       -0.04915474,  0.07122432,  0.38517377, -0.37048057, -0.0131752 ,\n",
       "        0.08253281,  0.01698119,  0.07444052, -0.10375332,  0.06932747,\n",
       "        0.16266349,  0.14340512,  0.07160636,  0.12850389, -0.02497635,\n",
       "       -0.04368549,  0.14294127, -0.14376868, -0.10754451,  0.17497635,\n",
       "        0.04113217,  0.11907446,  0.19428629,  0.02934513,  0.18947516,\n",
       "       -0.20436488,  0.24697264, -0.06854298,  0.04245058,  0.13546067,\n",
       "        0.10159183,  0.12136257,  0.01651067, -0.17904435, -0.13868104,\n",
       "       -0.23018797, -0.05750974, -0.21808766, -0.10608614, -0.04450681,\n",
       "       -0.2320594 , -0.10228968,  0.1599142 ,  0.09507775, -0.09630222,\n",
       "       -0.00252972, -0.13751638, -0.17197922,  0.02749155, -0.02923152,\n",
       "        0.00121597, -0.10725203, -0.0760405 ,  0.0272915 , -0.01232549,\n",
       "        0.0481954 , -0.03331024, -0.05303425,  0.06774193,  0.09432502,\n",
       "       -0.00544214,  0.08422698,  0.04973808, -0.05382266,  0.14491802,\n",
       "        0.0462805 , -0.09703044, -0.06729977, -0.04338542,  0.11160561,\n",
       "        0.00502238,  0.01709566,  0.15101376,  0.04545307,  0.14368454,\n",
       "        0.16490674,  0.10880293,  0.1544124 , -0.06257489, -0.05441578,\n",
       "        0.04309954, -0.10070109, -0.01209221,  0.06860472, -0.08871035])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.98535500e-03, 3.19372501e-03, 2.16570927e-02, 3.39028587e-03,\n",
       "       4.69209134e-03, 0.00000000e+00, 0.00000000e+00, 4.70902883e-03,\n",
       "       5.56024624e-03, 1.46065356e-02, 2.12302726e-03, 3.29893162e-03,\n",
       "       3.01179244e-03, 2.89845947e-03, 3.78655436e-03, 2.73391886e-03,\n",
       "       8.88348192e-04, 0.00000000e+00, 4.53312875e-03, 9.24367583e-03,\n",
       "       2.11583789e-03, 6.36271509e-03, 7.50202569e-03, 2.76628656e-03,\n",
       "       3.41554745e-03, 0.00000000e+00, 2.10009320e-03, 4.14409655e-03,\n",
       "       9.64295585e-03, 2.18093220e-03, 1.24247162e-02, 2.44751227e-03,\n",
       "       1.32815700e-03, 4.88160802e-03, 1.84231232e-03, 0.00000000e+00,\n",
       "       5.43662324e-04, 3.27005906e-03, 3.87591930e-03, 7.83911701e-03,\n",
       "       6.85093164e-03, 7.03348920e-03, 4.97959766e-03, 4.52443385e-02,\n",
       "       9.34408297e-04, 9.12481523e-03, 1.89514010e-03, 1.35228893e-02,\n",
       "       1.90840997e-03, 2.73941717e-03, 5.21208056e-03, 4.22379910e-02,\n",
       "       5.23869340e-03, 2.89201465e-03, 0.00000000e+00, 2.98644808e-03,\n",
       "       2.15163655e-03, 2.18886273e-03, 1.23912942e-02, 1.21815100e-03,\n",
       "       1.55550991e-02, 1.44434051e-03, 1.09880293e-03, 1.59070067e-01,\n",
       "       2.93526772e-03, 1.63366162e-03, 0.00000000e+00, 5.05712430e-03,\n",
       "       0.00000000e+00, 4.64003351e-03, 1.16875815e-19, 9.91087734e-03,\n",
       "       4.17877065e-03, 1.59903617e-03, 1.10077347e-03, 8.47222220e-03,\n",
       "       2.32571226e-03, 4.35953043e-03, 4.36882132e-04, 9.95832644e-03,\n",
       "       3.24082737e-03, 5.01329984e-03, 1.68643461e-03, 3.41889492e-03,\n",
       "       2.23922235e-03, 3.36581840e-03, 1.25712262e-02, 5.51314831e-02,\n",
       "       0.00000000e+00, 6.66991041e-03, 0.00000000e+00, 9.59625674e-04,\n",
       "       4.47380655e-03, 1.61194492e-02, 6.15563380e-02, 3.29411139e-02,\n",
       "       3.42950301e-03, 2.88971887e-03, 0.00000000e+00, 1.43222447e-03,\n",
       "       0.00000000e+00, 7.45949474e-03, 0.00000000e+00, 1.35537990e-03,\n",
       "       1.08073136e-03, 1.98301385e-03, 1.57527372e-03, 1.75454287e-02,\n",
       "       6.95835607e-03, 1.30516719e-03, 2.60289048e-04, 4.63056971e-03,\n",
       "       7.40138858e-03, 1.84468817e-03, 2.60801538e-03, 0.00000000e+00,\n",
       "       4.03799708e-03, 2.17835529e-03, 2.57479827e-03, 3.80600370e-03,\n",
       "       1.20659087e-02, 2.84556660e-03, 5.96672526e-03, 1.41800910e-03,\n",
       "       1.07798708e-02, 2.46780197e-03, 4.70558338e-03, 0.00000000e+00,\n",
       "       8.79335553e-03, 2.87870772e-03, 1.63978491e-03, 2.27310307e-03,\n",
       "       3.08823240e-03, 2.38501877e-03, 1.42557005e-02, 1.40688861e-03,\n",
       "       2.32941771e-03, 2.56393662e-03, 4.45011127e-02, 1.22875445e-03,\n",
       "       3.72208025e-03, 3.47855685e-03, 1.15283023e-03, 6.10037802e-04,\n",
       "       2.17627997e-03])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_Ada.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training & Testing Models\n",
    "\n",
    "0) Random Choice -> 0.5\n",
    "1) BoW N most common words -> 0.8299183430987688\n",
    "2) BoW N most common TF-IDF -> 0.828528161220805\n",
    "3) latent semantic analysis (word2vec w/ Logistic) -> 0.8169025569340089\n",
    "4) word2vec w/ AdaBoost -> 0.8239967383074145\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW common:\n",
    "Accuracy: 0.8285631079270779\n",
    "Precision: 0.6630522902310498\n",
    "Recall: 0.3648173961527739\n",
    "F1 score: 0.47066863288134375\n",
    "Balanced Accuracy: 0.6579277674328882\n",
    "\n",
    "BoW TF-IDF\n",
    "Accuracy: 0.828528161220805\n",
    "Precision: 0.6634801179701006\n",
    "Recall: 0.363758015054363\n",
    "F1 score: 0.46989340247767225\n",
    "Balanced Accuracy: 0.6575158798582079\n",
    "\n",
    "w2v Logistic: \n",
    "Accuracy: 0.8169025569340089\n",
    "Precision: 0.6208701341184167\n",
    "Recall: 0.3174797881237803\n",
    "F1 score: 0.4201283848594407\n",
    "Balanced Accuracy: 0.633139835160403\n",
    "\n",
    "AdaBoost:\n",
    "Accuracy: 0.8239967383074145\n",
    "Precision: 0.5981113734203582\n",
    "Recall: 0.4802899358795651\n",
    "F1 score: 0.5327643256950243\n",
    "Balanced Accuracy: 0.6975297419053251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49896907216494846\n",
      "Precision: 0.206328758139317\n",
      "Recall: 0.4911625313632562\n",
      "F1 score: 0.2905870128156493\n",
      "Balanced Accuracy: 0.4960966536951754\n"
     ]
    }
   ],
   "source": [
    "y_pred_rand = numpy.round(numpy.random.rand(len(df_test))).astype(int).astype(str)\n",
    "y_test = df_test[:,1]\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_rand))\n",
    "print('Precision:', precision_score(y_test, y_pred_rand, pos_label=\"1\"))\n",
    "print('Recall:', recall_score(y_test, y_pred_rand, pos_label=\"1\"))\n",
    "print('F1 score:', f1_score(y_test, y_pred_rand, pos_label=\"1\"))\n",
    "print('Balanced Accuracy:', balanced_accuracy_score(y_test, y_pred_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "p = 0\n",
    "r = 0\n",
    "f1 = 0\n",
    "ba = 0\n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=200\n",
    "for i in range(200):\n",
    "    y_pred_rand = numpy.round(numpy.random.rand(len(df_test))).astype(int).astype(str)\n",
    "    a += accuracy_score(y_test, y_pred_rand)\n",
    "    p += precision_score(y_test, y_pred_rand, pos_label=\"1\")\n",
    "    r += recall_score(y_test, y_pred_rand, pos_label=\"1\")\n",
    "    f1 += f1_score(y_test, y_pred_rand, pos_label=\"1\")\n",
    "    ba += balanced_accuracy_score(y_test, y_pred_rand)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.500054633350807\n",
      "Precision: 0.20893493834595833\n",
      "Recall: 0.49995525508781746\n",
      "F1 score: 0.29470822095286325\n",
      "Balanced Accuracy: 0.5000180670962576\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', a/n)\n",
    "print('Precision:', p/n)\n",
    "print('Recall:', r/n)\n",
    "print('F1 score:', f1/n)\n",
    "print('Balanced Accuracy:', ba/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21049336156258827"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "72279 / ( 271100+72279)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7895066384374118"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (72279 / ( 271100+72279))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14402"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(y_pred.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85845"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14366514708669587"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14402 / (85845 + 14402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8563348529133041"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (14402 / (85845 + 14402))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
